{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOonP1vTNHyZC7TneAwQwk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghenwafkh/AI-and-machine-learning/blob/master/ColBERT_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install colbert\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVGxhA1xYNpa",
        "outputId": "9dfb3344-0a54-4306-9693-d4ff908cdf4f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colbert\n",
            "  Downloading Colbert-0.30.tar.gz (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.0/79.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting icalendar (from colbert)\n",
            "  Downloading icalendar-5.0.11-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.1/112.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from colbert) (2023.3.post1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from icalendar->colbert) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->icalendar->colbert) (1.16.0)\n",
            "Building wheels for collected packages: colbert\n",
            "  Building wheel for colbert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colbert: filename=Colbert-0.30-py3-none-any.whl size=70358 sha256=8b395e47e8b02ce474e6ba1f4bc4bd9bcd94f753a6def290604a92ec3ec8b854\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/be/45/ab937e99a6976af70dbc3233c3e8efa17734303cc91443d9de\n",
            "Successfully built colbert\n",
            "Installing collected packages: icalendar, colbert\n",
            "Successfully installed colbert-0.30 icalendar-5.0.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/stanford-futuredata/ColBERT.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ksa1A14-ZjMG",
        "outputId": "cbcc321d-a221-4401-9ee9-b22c6ada6b0a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/stanford-futuredata/ColBERT.git\n",
            "  Cloning https://github.com/stanford-futuredata/ColBERT.git to /tmp/pip-req-build-0222rebt\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/stanford-futuredata/ColBERT.git /tmp/pip-req-build-0222rebt\n",
            "  Resolved https://github.com/stanford-futuredata/ColBERT.git to commit b53d8bbe6e83deeb7c76fc6b912da37554981a02\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bitarray (from colbert==0.2.0)\n",
            "  Downloading bitarray-2.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.4/287.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from colbert==0.2.0)\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from colbert==0.2.0) (2.2.5)\n",
            "Collecting git-python (from colbert==0.2.0)\n",
            "  Downloading git_python-1.0.3-py2.py3-none-any.whl (1.9 kB)\n",
            "Collecting python-dotenv (from colbert==0.2.0)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting ninja (from colbert==0.2.0)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from colbert==0.2.0) (1.11.3)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from colbert==0.2.0) (3.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from colbert==0.2.0) (4.66.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from colbert==0.2.0) (4.35.2)\n",
            "Collecting ujson (from colbert==0.2.0)\n",
            "  Downloading ujson-5.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.9/53.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert==0.2.0) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert==0.2.0) (9.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets->colbert==0.2.0)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets->colbert==0.2.0)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->colbert==0.2.0) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert==0.2.0) (2.31.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->colbert==0.2.0) (3.4.1)\n",
            "Collecting multiprocess (from datasets->colbert==0.2.0)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert==0.2.0) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->colbert==0.2.0) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert==0.2.0) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->colbert==0.2.0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert==0.2.0) (6.0.1)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->colbert==0.2.0) (3.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask->colbert==0.2.0) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->colbert==0.2.0) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->colbert==0.2.0) (8.1.7)\n",
            "Collecting gitpython (from git-python->colbert==0.2.0)\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->colbert==0.2.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->colbert==0.2.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->colbert==0.2.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->colbert==0.2.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->colbert==0.2.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy->colbert==0.2.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->colbert==0.2.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->colbert==0.2.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->colbert==0.2.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->colbert==0.2.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy->colbert==0.2.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy->colbert==0.2.0) (6.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->colbert==0.2.0) (1.10.13)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->colbert==0.2.0) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->colbert==0.2.0) (3.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->colbert==0.2.0) (3.13.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->colbert==0.2.0) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->colbert==0.2.0) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->colbert==0.2.0) (0.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->colbert==0.2.0) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->colbert==0.2.0) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->colbert==0.2.0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->colbert==0.2.0) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->colbert==0.2.0) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->colbert==0.2.0) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->colbert==0.2.0) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets->colbert==0.2.0) (4.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask->colbert==0.2.0) (2.1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->colbert==0.2.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->colbert==0.2.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->colbert==0.2.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->colbert==0.2.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->colbert==0.2.0) (0.1.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython->git-python->colbert==0.2.0)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->colbert==0.2.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->colbert==0.2.0) (2023.3.post1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython->git-python->colbert==0.2.0)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->colbert==0.2.0) (1.16.0)\n",
            "Building wheels for collected packages: colbert\n",
            "  Building wheel for colbert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colbert: filename=colbert-0.2.0-py3-none-any.whl size=104443 sha256=f9695afb4e5126ab337c17c7b39608f36c6faea94c2d19e382df9721f9fee365\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-khcqnsp2/wheels/35/55/01/fab5dc50e4d43182c2de558775cd224b752ae3570093befb0c\n",
            "Successfully built colbert\n",
            "Installing collected packages: ninja, bitarray, ujson, smmap, python-dotenv, pyarrow-hotfix, dill, multiprocess, gitdb, gitpython, git-python, datasets, colbert\n",
            "  Attempting uninstall: colbert\n",
            "    Found existing installation: Colbert 0.30\n",
            "    Uninstalling Colbert-0.30:\n",
            "      Successfully uninstalled Colbert-0.30\n",
            "Successfully installed bitarray-2.8.3 colbert-0.2.0 datasets-2.15.0 dill-0.3.7 git-python-1.0.3 gitdb-4.0.11 gitpython-3.1.40 multiprocess-0.70.15 ninja-1.11.1.1 pyarrow-hotfix-0.6 python-dotenv-1.0.0 smmap-5.0.1 ujson-5.8.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "colbert"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sJ0GFfDWZ1w",
        "outputId": "f6be1765-ec6d-4bf0-a3b5-93e8509f6743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: faiss must be imported for indexing\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.insert(0, '../')\n",
        "from colbert.infra import Run, RunConfig, ColBERTConfig\n",
        "from colbert.data import Queries, Collection\n",
        "from colbert import indexer, searcher"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p downloads/\n",
        "\n",
        "# ColBERTv2 checkpoint trained on MS MARCO Passage Ranking (388MB compressed)\n",
        "!wget https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/colbertv2.0.tar.gz -P downloads/\n",
        "!tar -xvzf downloads/colbertv2.0.tar.gz -C downloads/\n",
        "\n",
        "# The LoTTE dev and test sets (3.4GB compressed)\n",
        "!wget https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/lotte.tar.gz -P downloads/\n",
        "!tar -xvzf downloads/lotte.tar.gz -C downloads/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyhnf-Ynbh5O",
        "outputId": "ba95d185-e6c0-49da-d8e3-40f539c1b231"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-29 14:14:26--  https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/colbertv2.0.tar.gz\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 405924985 (387M) [application/octet-stream]\n",
            "Saving to: ‘downloads/colbertv2.0.tar.gz’\n",
            "\n",
            "colbertv2.0.tar.gz  100%[===================>] 387.12M  5.13MB/s    in 72s     \n",
            "\n",
            "2023-11-29 14:15:38 (5.36 MB/s) - ‘downloads/colbertv2.0.tar.gz’ saved [405924985/405924985]\n",
            "\n",
            "colbertv2.0/\n",
            "colbertv2.0/artifact.metadata\n",
            "colbertv2.0/vocab.txt\n",
            "colbertv2.0/tokenizer.json\n",
            "colbertv2.0/special_tokens_map.json\n",
            "colbertv2.0/tokenizer_config.json\n",
            "colbertv2.0/config.json\n",
            "colbertv2.0/pytorch_model.bin\n",
            "--2023-11-29 14:15:45--  https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/lotte.tar.gz\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3576167599 (3.3G) [application/octet-stream]\n",
            "Saving to: ‘downloads/lotte.tar.gz’\n",
            "\n",
            "lotte.tar.gz        100%[===================>]   3.33G  5.13MB/s    in 11m 21s \n",
            "\n",
            "2023-11-29 14:27:06 (5.01 MB/s) - ‘downloads/lotte.tar.gz’ saved [3576167599/3576167599]\n",
            "\n",
            "lotte/\n",
            "lotte/science/\n",
            "lotte/science/test/\n",
            "lotte/science/test/questions.search.tsv\n",
            "lotte/science/test/questions.forum.tsv\n",
            "lotte/science/test/collection.tsv\n",
            "lotte/science/test/qas.forum.jsonl\n",
            "lotte/science/test/metadata.jsonl\n",
            "lotte/science/test/qas.search.jsonl\n",
            "lotte/science/dev/\n",
            "lotte/science/dev/questions.search.tsv\n",
            "lotte/science/dev/questions.forum.tsv\n",
            "lotte/science/dev/collection.tsv\n",
            "lotte/science/dev/qas.forum.jsonl\n",
            "lotte/science/dev/metadata.jsonl\n",
            "lotte/science/dev/qas.search.jsonl\n",
            "lotte/writing/\n",
            "lotte/writing/test/\n",
            "lotte/writing/test/questions.search.tsv\n",
            "lotte/writing/test/questions.forum.tsv\n",
            "lotte/writing/test/collection.tsv\n",
            "lotte/writing/test/qas.forum.jsonl\n",
            "lotte/writing/test/metadata.jsonl\n",
            "lotte/writing/test/qas.search.jsonl\n",
            "lotte/writing/dev/\n",
            "lotte/writing/dev/questions.search.tsv\n",
            "lotte/writing/dev/questions.forum.tsv\n",
            "lotte/writing/dev/collection.tsv\n",
            "lotte/writing/dev/qas.forum.jsonl\n",
            "lotte/writing/dev/metadata.jsonl\n",
            "lotte/writing/dev/qas.search.jsonl\n",
            "lotte/recreation/\n",
            "lotte/recreation/test/\n",
            "lotte/recreation/test/questions.search.tsv\n",
            "lotte/recreation/test/questions.forum.tsv\n",
            "lotte/recreation/test/collection.tsv\n",
            "lotte/recreation/test/qas.forum.jsonl\n",
            "lotte/recreation/test/metadata.jsonl\n",
            "lotte/recreation/test/qas.search.jsonl\n",
            "lotte/recreation/dev/\n",
            "lotte/recreation/dev/questions.search.tsv\n",
            "lotte/recreation/dev/questions.forum.tsv\n",
            "lotte/recreation/dev/collection.tsv\n",
            "lotte/recreation/dev/qas.forum.jsonl\n",
            "lotte/recreation/dev/metadata.jsonl\n",
            "lotte/recreation/dev/qas.search.jsonl\n",
            "lotte/lifestyle/\n",
            "lotte/lifestyle/test/\n",
            "lotte/lifestyle/test/questions.search.tsv\n",
            "lotte/lifestyle/test/questions.forum.tsv\n",
            "lotte/lifestyle/test/collection.tsv\n",
            "lotte/lifestyle/test/qas.forum.jsonl\n",
            "lotte/lifestyle/test/metadata.jsonl\n",
            "lotte/lifestyle/test/qas.search.jsonl\n",
            "lotte/lifestyle/dev/\n",
            "lotte/lifestyle/dev/questions.search.tsv\n",
            "lotte/lifestyle/dev/questions.forum.tsv\n",
            "lotte/lifestyle/dev/collection.tsv\n",
            "lotte/lifestyle/dev/qas.forum.jsonl\n",
            "lotte/lifestyle/dev/metadata.jsonl\n",
            "lotte/lifestyle/dev/qas.search.jsonl\n",
            "lotte/evaluate_lotte_rankings.py\n",
            "lotte/technology/\n",
            "lotte/technology/test/\n",
            "lotte/technology/test/questions.search.tsv\n",
            "lotte/technology/test/questions.forum.tsv\n",
            "lotte/technology/test/collection.tsv\n",
            "lotte/technology/test/qas.forum.jsonl\n",
            "lotte/technology/test/metadata.jsonl\n",
            "lotte/technology/test/qas.search.jsonl\n",
            "lotte/technology/dev/\n",
            "lotte/technology/dev/questions.search.tsv\n",
            "lotte/technology/dev/questions.forum.tsv\n",
            "lotte/technology/dev/collection.tsv\n",
            "lotte/technology/dev/qas.forum.jsonl\n",
            "lotte/technology/dev/metadata.jsonl\n",
            "lotte/technology/dev/qas.search.jsonl\n",
            "lotte/pooled/\n",
            "lotte/pooled/test/\n",
            "lotte/pooled/test/questions.search.tsv\n",
            "lotte/pooled/test/questions.forum.tsv\n",
            "lotte/pooled/test/collection.tsv\n",
            "lotte/pooled/test/qas.forum.jsonl\n",
            "lotte/pooled/test/qas.search.jsonl\n",
            "lotte/pooled/dev/\n",
            "lotte/pooled/dev/questions.search.tsv\n",
            "lotte/pooled/dev/questions.forum.tsv\n",
            "lotte/pooled/dev/collection.tsv\n",
            "lotte/pooled/dev/qas.forum.jsonl\n",
            "lotte/pooled/dev/qas.search.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataroot = 'downloads/lotte'\n",
        "dataset = 'lifestyle'\n",
        "datasplit = 'dev'\n",
        "\n",
        "queries = os.path.join(dataroot, dataset, datasplit, 'questions.search.tsv')\n",
        "collection = os.path.join(dataroot, dataset, datasplit, 'collection.tsv')\n",
        "\n",
        "queries = Queries(path=queries)\n",
        "collection = Collection(path=collection)\n",
        "\n",
        "f'Loaded {len(queries)} queries and {len(collection):,} passages'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "FWGtb1xxbwWu",
        "outputId": "74d379b7-dd3c-4373-efd5-622d917f8bfe"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Nov 29, 14:32:24] #> Loading the queries from downloads/lotte/lifestyle/dev/questions.search.tsv ...\n",
            "[Nov 29, 14:32:24] #> Got 417 queries. All QIDs are unique.\n",
            "\n",
            "[Nov 29, 14:32:24] #> Loading collection...\n",
            "0M \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Loaded 417 queries and 268,893 passages'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(queries[24])\n",
        "print()\n",
        "print(collection[89852])\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b20n3tQHfvMV",
        "outputId": "84ea3702-f16c-46f3-d450-8d1110109255"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "are blossom end rot tomatoes edible?\n",
            "\n",
            "I don't know what J-Rock is definitively as it could mean a number of things, however if you mean a 'metal' style rock guitar sound that I believe to be popular over there, then it can be quite simple: Strip all of your pedals and effects, and turn all dials to zero; Turn the volume up as far as it will go; Keep the Bass and Treble dials high; Turn down any 'Middle' dials until the sound becomes scooped - bear in the mind that middle frequencies are important for clarity, so find a decent compromise; Bring up the gain until you get the sound you require; Finally, bring the volume down to a more manageable level. This will get you a lot of the way, but without any clearer description of what you want to sound like, then I can't offer any more help.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nbits = 2   # encode each dimension with 2 bits\n",
        "doc_maxlen = 300   # truncate passages at 300 tokens\n",
        "\n",
        "checkpoint = 'downloads/colbertv2.0'\n",
        "index_name = f'{dataset}.{datasplit}.{nbits}bits'"
      ],
      "metadata": {
        "id": "SIvl5680jL4z"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(checkpoint)\n",
        "print(index_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76SdZmqGjOQ5",
        "outputId": "d4ae373c-9a0c-4359-cd5e-5a40679d8ae2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloads/colbertv2.0\n",
            "lifestyle.dev.2bits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with Run().context(RunConfig(nranks=4, experiment='notebook')):  # nranks specifies the number of GPUs to use.\n",
        "    config = ColBERTConfig(doc_maxlen=doc_maxlen, nbits=nbits)\n",
        "\n",
        "    indexer = indexer.Indexer(checkpoint=checkpoint, config=config)\n",
        "    indexer.index(name=index_name, collection=collection, overwrite=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClOiFIgFjfP4",
        "outputId": "6565aced-dd4a-4f15-bbc8-6d79fb72e5d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "[Nov 29, 14:50:15] #> Creating directory /content/experiments/notebook/indexes/lifestyle.dev.2bits \n",
            "\n",
            "\n",
            "#> Starting...\n",
            "#> Starting...\n",
            "#> Starting...\n",
            "#> Starting...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = queries[37]   # or supply your own query\n",
        "\n",
        "print(f\"#> {query}\")\n",
        "\n",
        "# Find the top-3 passages for this query\n",
        "results = searcher.search(query, k=3)\n",
        "\n",
        "# Print out the top-k retrieved passages\n",
        "for passage_id, passage_rank, passage_score in zip(*results):\n",
        "    print(f\"\\t [{passage_rank}] \\t\\t {passage_score:.1f} \\t\\t {searcher.collection[passage_id]}\")"
      ],
      "metadata": {
        "id": "NzphBE9DnyRb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}